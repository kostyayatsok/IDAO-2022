{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUZGR6D82ij-"
      },
      "source": [
        "# [ALIGNN](https://github.com/usnistgov/alignn) example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFrl_N-S1Bxk",
        "outputId": "7ab75ecd-7529-41ab-e3d2-70fa97093dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 61 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 79 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 785 kB/s \n",
            "\u001b[K     |████████████████████████████████| 251 kB 13.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 954 kB 37.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 32.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 132 kB/s \n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 17.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 292 kB 40.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qqq alignn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyyE-cHL2iOn",
        "outputId": "d7dc0e3e-00cf-4ba7-869c-5df7e3d0438f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'alignn'...\n",
            "remote: Enumerating objects: 2158, done.\u001b[K\n",
            "remote: Counting objects: 100% (2158/2158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1128/1128), done.\u001b[K\n",
            "remote: Total 2158 (delta 1376), reused 1642 (delta 960), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2158/2158), 1.25 MiB | 9.43 MiB/s, done.\n",
            "Resolving deltas: 100% (1376/1376), done.\n",
            "Collecting dgl-cu111\n",
            "  Downloading dgl_cu111-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (41.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.0 MB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2021.10.8)\n",
            "Installing collected packages: dgl-cu111\n",
            "Successfully installed dgl-cu111-0.6.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Clone ALIGNN repo to get example folder\n",
        "if not os.path.exists('alignn'):\n",
        "  !git clone https://github.com/usnistgov/alignn.git\n",
        "\n",
        "os.chdir('alignn')\n",
        "# Install using setup.py in case pip didn't work\n",
        "# !python setup.py develop\n",
        "\n",
        "!pip install dgl-cu111 # Colab has cuda 11.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKyGxe4pozLo"
      },
      "source": [
        "## prepare IDAO data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb30n15Soyyg",
        "outputId": "04912ce2-5d31-4cec-8b03-a65acb419dc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IDAO-2022'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 22 (delta 2), reused 19 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), done.\n",
            "\u001b[K     |████████████████████████████████| 40.6 MB 2.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 37.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 47.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 546 kB 52.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 35.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 53.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for pymatgen (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HSE-LAMBDA/IDAO-2022.git\n",
        "!cd IDAO-2022/data && tar -xf dichalcogenides_public.tar.gz\n",
        "%pip install -qqq pymatgen wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMnzMMC_pBp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c746ed-00de-4554-d0db-9365a858ff50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'dataset_path/POSCAR': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from pymatgen.core import Structure\n",
        "import os\n",
        "\n",
        "def convert_to_POSCAR(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        d = json.load(f)\n",
        "    s = Structure.from_dict(d)\n",
        "\n",
        "    parts = list(file.parts)\n",
        "    parts[-1] = file.stem + \".vasp\"\n",
        "    parts[-2] = \"POSCAR\"\n",
        "    new_file = Path(*parts)\n",
        "    \n",
        "    s.to(fmt=\"poscar\", filename=new_file)\n",
        "\n",
        "def convert_dataset_to_POSCAR(dataset_path):\n",
        "    dataset_path = Path(dataset_path)\n",
        "\n",
        "    ! rm -r dataset_path/\"POSCAR\"\n",
        "    os.makedirs(dataset_path/\"POSCAR\", exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        targets = pd.read_csv(dataset_path / \"targets.csv\")\n",
        "        targets._id = targets._id + \".vasp\"\n",
        "        targets.to_csv(dataset_path/\"POSCAR\"/\"id_prop.csv\", index=False, header=False)\n",
        "    except:\n",
        "        pass\n",
        "    for item in (dataset_path / \"structures\").iterdir():\n",
        "        convert_to_POSCAR(item)\n",
        "\n",
        "\n",
        "convert_dataset_to_POSCAR('./IDAO-2022/data/dichalcogenides_public/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbzuGCA332yS"
      },
      "source": [
        "# Train a model. Parameters are provided in `config_example.json` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNHla4FDKRre"
      },
      "source": [
        "Command line train_folder.py is used below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo4u6PIQEZBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a75c4c0-afed-419f-c384-bade917021b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'temp': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.json\n",
        "{\n",
        "    \"version\": \"112bbedebdaecf59fb18e11c929080fb2f358246\",\n",
        "    \"dataset\": \"user_data\",\n",
        "    \"target\": \"target\",\n",
        "    \"atom_features\": \"cgcnn\",\n",
        "    \"neighbor_strategy\": \"k-nearest\",\n",
        "    \"id_tag\": \"jid\",\n",
        "    \"random_seed\": 123,\n",
        "    \"classification_threshold\": null,\n",
        "    \"n_val\": null,\n",
        "    \"n_test\": null,\n",
        "    \"n_train\": null,\n",
        "    \"train_ratio\": 0.8,\n",
        "    \"val_ratio\": 0.1,\n",
        "    \"test_ratio\": 0.1,\n",
        "    \"target_multiplication_factor\": null,\n",
        "    \"epochs\": 200,\n",
        "    \"batch_size\": 8,\n",
        "    \"weight_decay\": 1e-05,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"filename\": \"sample\",\n",
        "    \"warmup_steps\": 2000,\n",
        "    \"criterion\": \"mse\",\n",
        "    \"optimizer\": \"adamw\",\n",
        "    \"scheduler\": \"onecycle\",\n",
        "    \"pin_memory\": false,\n",
        "    \"save_dataloader\": false,\n",
        "    \"write_checkpoint\": true,\n",
        "    \"write_predictions\": false,\n",
        "    \"store_outputs\": true,\n",
        "    \"progress\": true,\n",
        "    \"log_tensorboard\": false,\n",
        "    \"standard_scalar_and_pca\": false,\n",
        "    \"use_canonize\": true,\n",
        "    \"num_workers\": 0,\n",
        "    \"cutoff\": 8.0,\n",
        "    \"max_neighbors\": 12,\n",
        "    \"keep_data_order\": false,\n",
        "    \"model\": {\n",
        "        \"name\": \"alignn\",\n",
        "        \"alignn_layers\": 4,\n",
        "        \"gcn_layers\": 4,\n",
        "        \"atom_input_features\": 92,\n",
        "        \"edge_input_features\": 80,\n",
        "        \"triplet_input_features\": 40,\n",
        "        \"embedding_features\": 64,\n",
        "        \"hidden_features\": 128,\n",
        "        \"output_features\": 1,\n",
        "        \"link\": \"identity\",\n",
        "        \"zero_inflated\": false,\n",
        "        \"classification\": false\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQCA4KrhlgFc",
        "outputId": "5a2e1334-e683-4761-8e07-7a881a66e9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5JkSMwx2cfy",
        "outputId": "9b50ef38-a171-41bb-8fdd-c4758e429c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using backend: pytorch\n",
            "MAX val: 1.8106\n",
            "MIN val: 0.0938999999999999\n",
            "MAD: 0.4596230686826515\n",
            "Baseline MAE: 0.45039721269541044\n",
            "data range 1.8106 0.1720999999999999\n",
            "  0% 0/2372 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/jarvis/core/graphs.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  r = torch.tensor(r).type(torch.get_default_dtype())\n",
            "100% 2372/2372 [06:55<00:00,  5.70it/s]\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 2372/2372 [00:47<00:00, 50.29it/s]\n",
            "data range 1.8103 0.2542\n",
            "100% 296/296 [00:50<00:00,  5.83it/s]\n",
            "building line graphs\n",
            "100% 296/296 [00:05<00:00, 50.40it/s]\n",
            "data range 1.8103 0.0938999999999999\n",
            "100% 296/296 [00:50<00:00,  5.83it/s]\n",
            "building line graphs\n",
            "100% 296/296 [00:05<00:00, 50.18it/s]\n",
            "n_train: 2372\n",
            "n_val: 296\n",
            "n_test: 296\n",
            "version='112bbedebdaecf59fb18e11c929080fb2f358246' dataset='user_data' target='target' atom_features='cgcnn' neighbor_strategy='k-nearest' id_tag='jid' random_seed=123 classification_threshold=None n_val=None n_test=None n_train=None train_ratio=0.8 val_ratio=0.1 test_ratio=0.1 target_multiplication_factor=None epochs=200 batch_size=8 weight_decay=1e-05 learning_rate=0.001 filename='sample' warmup_steps=2000 criterion='mse' optimizer='adamw' scheduler='onecycle' pin_memory=False save_dataloader=False write_checkpoint=True write_predictions=False store_outputs=True progress=True log_tensorboard=False standard_scalar_and_pca=False use_canonize=True num_workers=0 cutoff=8.0 max_neighbors=12 keep_data_order=False distributed=False n_early_stopping=None output_dir='temp' model=ALIGNNConfig(name='alignn', alignn_layers=4, gcn_layers=4, atom_input_features=92, edge_input_features=80, triplet_input_features=40, embedding_features=64, hidden_features=128, output_features=1, link='identity', zero_inflated=False, classification=False)\n",
            "config:\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 8,\n",
            " 'classification_threshold': None,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 8.0,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'epochs': 200,\n",
            " 'filename': 'sample',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': False,\n",
            " 'learning_rate': 0.001,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 4,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 64,\n",
            "           'gcn_layers': 4,\n",
            "           'hidden_features': 128,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': None,\n",
            " 'n_test': None,\n",
            " 'n_train': None,\n",
            " 'n_val': None,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'num_workers': 0,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': 'temp',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 123,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': False,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': '112bbedebdaecf59fb18e11c929080fb2f358246',\n",
            " 'warmup_steps': 2000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': False}\n",
            "Val_MAE: 0.1452\n",
            "Train_MAE: 0.1290\n",
            "Val_MAE: 0.2865\n",
            "Train_MAE: 0.2883\n",
            "Val_MAE: 0.1193\n",
            "Train_MAE: 0.1025\n",
            "Val_MAE: 0.1507\n",
            "Train_MAE: 0.1427\n",
            "Val_MAE: 0.1285\n",
            "Train_MAE: 0.1216\n",
            "Val_MAE: 0.0901\n",
            "Train_MAE: 0.0780\n",
            "Val_MAE: 0.1982\n",
            "Train_MAE: 0.1854\n",
            "Val_MAE: 0.2046\n",
            "Train_MAE: 0.1970\n",
            "Val_MAE: 0.0656\n",
            "Train_MAE: 0.0603\n",
            "Val_MAE: 0.1184\n",
            "Train_MAE: 0.1057\n",
            "Val_MAE: 0.3328\n",
            "Train_MAE: 0.3475\n",
            "Val_MAE: 0.2300\n",
            "Train_MAE: 0.2326\n",
            "Val_MAE: 0.0527\n",
            "Train_MAE: 0.0495\n",
            "Val_MAE: 0.3882\n",
            "Train_MAE: 0.3776\n",
            "Val_MAE: 0.2458\n",
            "Train_MAE: 0.2289\n",
            "Val_MAE: 0.0902\n",
            "Train_MAE: 0.0852\n",
            "Val_MAE: 0.1213\n",
            "Train_MAE: 0.0977\n",
            "Val_MAE: 0.1113\n",
            "Train_MAE: 0.1080\n",
            "Val_MAE: 0.0854\n",
            "Train_MAE: 0.0776\n",
            "Val_MAE: 0.0741\n",
            "Train_MAE: 0.0758\n",
            "Val_MAE: 0.0912\n",
            "Train_MAE: 0.0800\n",
            "Val_MAE: 0.0894\n",
            "Train_MAE: 0.0858\n",
            "Val_MAE: 0.0471\n",
            "Train_MAE: 0.0453\n",
            "Val_MAE: 0.1237\n",
            "Train_MAE: 0.1272\n",
            "Val_MAE: 0.1337\n",
            "Train_MAE: 0.1361\n",
            "Val_MAE: 0.0577\n",
            "Train_MAE: 0.0526\n",
            "Val_MAE: 0.4415\n",
            "Train_MAE: 0.4398\n",
            "Val_MAE: 0.0700\n",
            "Train_MAE: 0.0675\n",
            "Val_MAE: 0.0697\n",
            "Train_MAE: 0.0703\n",
            "Val_MAE: 0.0908\n",
            "Train_MAE: 0.0927\n",
            "Val_MAE: 0.0751\n",
            "Train_MAE: 0.0752\n",
            "Val_MAE: 0.1362\n",
            "Train_MAE: 0.1374\n",
            "Val_MAE: 0.0739\n",
            "Train_MAE: 0.0727\n",
            "Val_MAE: 0.0964\n",
            "Train_MAE: 0.0984\n",
            "Val_MAE: 0.1849\n",
            "Train_MAE: 0.1825\n",
            "Val_MAE: 0.4570\n",
            "Train_MAE: 0.4448\n",
            "Val_MAE: 0.0209\n",
            "Train_MAE: 0.0192\n",
            "Val_MAE: 0.0399\n",
            "Train_MAE: 0.0380\n",
            "Val_MAE: 0.0872\n",
            "Train_MAE: 0.0850\n",
            "Val_MAE: 0.0874\n",
            "Train_MAE: 0.0880\n",
            "Val_MAE: 0.1485\n",
            "Train_MAE: 0.1513\n",
            "Val_MAE: 0.0839\n",
            "Train_MAE: 0.0857\n",
            "Val_MAE: 0.0411\n",
            "Train_MAE: 0.0410\n",
            "Val_MAE: 0.0621\n",
            "Train_MAE: 0.0575\n",
            "Val_MAE: 0.0517\n",
            "Train_MAE: 0.0457\n",
            "Val_MAE: 0.0360\n",
            "Train_MAE: 0.0342\n",
            "Val_MAE: 0.0233\n",
            "Train_MAE: 0.0211\n",
            "Val_MAE: 0.0264\n",
            "Train_MAE: 0.0238\n",
            "Val_MAE: 0.1050\n",
            "Train_MAE: 0.1024\n",
            "Val_MAE: 0.0312\n",
            "Train_MAE: 0.0301\n",
            "Val_MAE: 0.0275\n",
            "Train_MAE: 0.0232\n",
            "Engine run is terminating due to exception: \n",
            "Engine run is terminating due to exception: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/train_folder.py\", line 205, in <module>\n",
            "    file_format=(args.file_format),\n",
            "  File \"/usr/local/bin/train_folder.py\", line 186, in train_for_folder\n",
            "    prepare_batch,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/alignn/train.py\", line 504, in train_dgl\n",
            "    trainer.run(train_loader, max_epochs=config.epochs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 704, in run\n",
            "    return self._internal_run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 783, in _internal_run\n",
            "    self._handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 466, in _handle_exception\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 760, in _internal_run\n",
            "    self._fire_event(Events.EPOCH_COMPLETED)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 421, in _fire_event\n",
            "    func(*first, *(event_args + others), **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/alignn/train.py\", line 427, in log_results\n",
            "    train_evaluator.run(train_loader)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 704, in run\n",
            "    return self._internal_run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 783, in _internal_run\n",
            "    self._handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 466, in _handle_exception\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 753, in _internal_run\n",
            "    time_taken = self._run_once_on_dataset()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 840, in _run_once_on_dataset\n",
            "    self.state.output = self._process_function(self, self.state.batch)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/__init__.py\", line 597, in evaluate_step\n",
            "    y_pred = model(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/alignn/models/alignn.py\", line 294, in forward\n",
            "    x, y = gcn_layer(g, x, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/alignn/models/alignn.py\", line 99, in forward\n",
            "    g.ndata[\"e_src\"] = self.src_gate(node_feats)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1848, in linear\n",
            "    return torch._C._nn.linear(input, weight, bias)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!train_folder.py --root_dir \"IDAO-2022/data/dichalcogenides_public/POSCAR/\" --config config.json --output_dir=temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bh6Fk03Zyno"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "latest = 0\n",
        "weight_ = None\n",
        "for weight in glob.glob(\"temp/*.pt\"):\n",
        "    epoch = int(weight.split('_')[-1].split('.')[0])  \n",
        "    if epoch > latest:\n",
        "        latest = epoch\n",
        "        weight_ = weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0_MQgzjbabz4",
        "outputId": "94e3a473-d475-4b2d-afad-b7353665189e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a71babb7-edc3-4c8c-b50d-71ce908107ae\", \"checkpoint_52.pt\", 12680169)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(weight_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYrs1vgkSlVl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "true = pd.read_csv(\"IDAO-2022/data/dichalcogenides_public/POSCAR/id_prop.csv\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UHNEOKn0NMI-",
        "outputId": "6fa73b94-4668-4817-bb5e-cddff6499e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-65c884d2f8dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALIGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALIGNNConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"alignn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1483\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ALIGNN:\n\tsize mismatch for atom_embedding.layer.0.weight: copying a param with shape torch.Size([128, 92]) from checkpoint, the shape in current model is torch.Size([256, 92]).\n\tsize mismatch for atom_embedding.layer.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for atom_embedding.layer.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for atom_embedding.layer.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for atom_embedding.layer.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for atom_embedding.layer.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for edge_embedding.2.layer.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for edge_embedding.2.layer.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for edge_embedding.2.layer.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for edge_embedding.2.layer.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for edge_embedding.2.layer.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for edge_embedding.2.layer.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for angle_embedding.2.layer.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([256, 64]).\n\tsize mismatch for angle_embedding.2.layer.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for angle_embedding.2.layer.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for angle_embedding.2.layer.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for angle_embedding.2.layer.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for angle_embedding.2.layer.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.node_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.node_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.node_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.node_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.node_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.node_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.edge_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.edge_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.edge_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.edge_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.0.edge_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.0.edge_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.node_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.node_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.node_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.node_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.node_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.node_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.edge_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.edge_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.edge_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.edge_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.1.edge_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.1.edge_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.node_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.node_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.node_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.node_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.node_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.node_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.edge_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.edge_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.edge_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.edge_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.2.edge_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.2.edge_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.node_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.node_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.node_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.node_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.node_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.node_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.edge_update.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.edge_update.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.edge_update.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.edge_update.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for alignn_layers.3.edge_update.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for alignn_layers.3.edge_update.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.0.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.0.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.0.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.0.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.0.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.0.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.1.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.1.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.1.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.1.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.1.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.1.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.2.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.2.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.2.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.2.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.2.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.2.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.src_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.3.src_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.dst_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.3.dst_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.edge_gate.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.3.edge_gate.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_edges.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_edges.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_edges.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_edges.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.src_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.3.src_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.dst_update.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 256]).\n\tsize mismatch for gcn_layers.3.dst_update.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_nodes.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_nodes.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_nodes.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for gcn_layers.3.bn_nodes.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 256])."
          ]
        }
      ],
      "source": [
        "from alignn.models.alignn import ALIGNN, ALIGNNConfig\n",
        "from alignn.pretrained import get_multiple_predictions\n",
        "import torch\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "from alignn.config import TrainingConfig\n",
        "from jarvis.core.atoms import Atoms\n",
        "\n",
        "model = ALIGNN(ALIGNNConfig(name=\"alignn\", output_features=1))\n",
        "model.load_state_dict(torch.load(weight_, map_location='cuda:0')[\"model\"])\n",
        "model.to('cuda:0')\n",
        "model.eval()\n",
        "\n",
        "import glob\n",
        "atoms_array = []\n",
        "for name in true[0]:\n",
        "    i = f\"IDAO-2022/data/dichalcogenides_public/POSCAR/{name}\"\n",
        "    atoms = Atoms.from_poscar(i)\n",
        "    atoms_array.append(atoms)\n",
        "get_multiple_predictions(model=model, atoms_array=atoms_array)\n",
        "\n",
        "with open(\"pred_data.json\") as f:\n",
        "    data = json.load(f)\n",
        "pred = pd.DataFrame.from_dict(data)\n",
        "pred = pred.drop(columns=\"atoms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D373QHhHaijk"
      },
      "outputs": [],
      "source": [
        "files.download(\"pred_data.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDY1MQBtWJLe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def energy_within_threshold(prediction, target):\n",
        "    # compute absolute error on energy per system.\n",
        "    # then count the no. of systems where max energy error is < 0.02.\n",
        "    e_thresh = 0.02\n",
        "    error_energy = np.abs(target - prediction)\n",
        "\n",
        "    success = np.count_nonzero(error_energy < e_thresh)\n",
        "    total = target.shape[0]\n",
        "    return success / total\n",
        "energy_within_threshold(pred.pred, true[1]), np.mean(np.abs(pred.pred - true[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwp73hUiOsLr"
      },
      "source": [
        "# Prepare test data and predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFJx9uc1OviI"
      },
      "outputs": [],
      "source": [
        "!cd IDAO-2022/data && tar -xf dichalcogenides_private.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4uXuHxAPcBe"
      },
      "outputs": [],
      "source": [
        "!cp IDAO-2022/submission.csv IDAO-2022/data/dichalcogenides_private/targets.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzWgVDTaO2Wy"
      },
      "outputs": [],
      "source": [
        "convert_dataset_to_POSCAR('./IDAO-2022/data/dichalcogenides_private/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMX9eBSZPRoz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "submission = pd.read_csv(\"IDAO-2022/submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWLJGEOEPGTS"
      },
      "outputs": [],
      "source": [
        "from alignn.models.alignn import ALIGNN, ALIGNNConfig\n",
        "from alignn.pretrained import get_multiple_predictions\n",
        "import torch\n",
        "from jarvis.db.jsonutils import loadjson\n",
        "from alignn.config import TrainingConfig\n",
        "from jarvis.core.atoms import Atoms\n",
        "\n",
        "weight_ = \"./checkpoint_200.pt\"\n",
        "\n",
        "model = ALIGNN(ALIGNNConfig(name=\"alignn\", output_features=1))\n",
        "model.load_state_dict(torch.load(weight_, map_location='cuda:0')[\"model\"])\n",
        "model.to('cuda:0')\n",
        "model.eval()\n",
        "\n",
        "import glob\n",
        "atoms_array = []\n",
        "for name in submission[\"id\"]:\n",
        "    i = f\"IDAO-2022/data/dichalcogenides_private/POSCAR/{name}.vasp\"\n",
        "    atoms = Atoms.from_poscar(i)\n",
        "    atoms_array.append(atoms)\n",
        "get_multiple_predictions(model=model, atoms_array=atoms_array)\n",
        "\n",
        "with open(\"pred_data.json\") as f:\n",
        "    data = json.load(f)\n",
        "pred = pd.DataFrame.from_dict(data)\n",
        "pred = pred.drop(columns=\"atoms\")\n",
        "\n",
        "submission[\"predictions\"] = pred[\"pred\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0z5WsG6TaiV"
      },
      "outputs": [],
      "source": [
        "submission[\"predictions\"] = pred[\"pred\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b99a7Zx0Tnre"
      },
      "outputs": [],
      "source": [
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUabfJFkPCJK"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "files.download(\"submission.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IDAO-2022-ALIGNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}